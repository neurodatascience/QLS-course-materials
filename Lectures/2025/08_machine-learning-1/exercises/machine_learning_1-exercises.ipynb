{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning Part 1: Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Training and testing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data from the Autism Brain Imaging Data Exchange (ABIDE) dataset. \n",
    "The data has already been downloaded and preprocessed into two TSV tables:\n",
    "- [`participants_nbsub-100.tsv`](../../data/participants_nbsub-100.tsv)\n",
    "    - Phenotypic information: participant age, sex, scan site, diagnosis, etc.\n",
    "- [`abide_nbsub-100_atlas-ho_meas-correlation_relmat.tsv`](../../data/abide_nbsub-100_atlas-ho_meas-correlation_relmat.tsv)\n",
    "    - Flattened functional connectivity matrixes\n",
    "\n",
    "The script used to create these files can be found [here](../../data/build_datasets.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and display the phenotypic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = \"../../data\"\n",
    "\n",
    "# phenotypic data (including diagnosis group DX_GROUP)\n",
    "pheno_data_tsv = f\"{data_dir}/participants_nbsub-100.tsv\"\n",
    "pheno_df = pd.read_csv(pheno_data_tsv, sep=\"\\t\", index_col=0)\n",
    "pheno_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the brain data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain data: functional connectivity matrices (flattened)\n",
    "brain_data_tsv = f\"{data_dir}/abide_nbsub-100_atlas-ho_meas-correlation_relmat.tsv\"\n",
    "brain_df = pd.read_csv(brain_data_tsv, sep=\"\\t\", index_col=0)\n",
    "brain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try predicting diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to predict diagnosis using the functional connectivity measures.\n",
    "\n",
    "First, let's write a helper function that takes as input a matrix `X`, a vector `y` and an `sklearn` model `model`. The function should:\n",
    "1. Split the data into train and test sets\n",
    "2. Fit the model on the train data\n",
    "3. Compute and print model performance on the train and test sets\n",
    "4. Return the fitted classifier model\n",
    "\n",
    "Write/modify the code in the cell below where it says `TODO`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_and_test_model(\n",
    "    model,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    test_subset_fraction=0.2,\n",
    "    shuffle=True,\n",
    "    do_stratify=True,\n",
    "    random_state=123,\n",
    "):\n",
    "    \"\"\"Train and test a scikit-learn model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        The scikit-learn model to be trained and tested\n",
    "    X : pd.DataFrame\n",
    "        Input features\n",
    "    y : pd.Series\n",
    "        Output labels\n",
    "    test_subset_fraction : float, optional\n",
    "        Fraction of the dataset to use for testing, by default 0.2\n",
    "    shuffle : bool, optional\n",
    "        Whether to shuffle the data before splitting, by default True\n",
    "    random_state : int, optional\n",
    "        Seed to force the shuffle to be the same each time, by default 123\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        The fitted model\n",
    "    \"\"\"\n",
    "    if do_stratify:\n",
    "        # ensure similar distribution of classes in train and test sets\n",
    "        stratify = y\n",
    "    else:\n",
    "        stratify = None\n",
    "\n",
    "    # TODO divide the data into train/test sets\n",
    "    # Hint: use sklearn's train_test_split function here\n",
    "    #       make sure to use test_subset_fraction, shuffle, stratify, and random_state\n",
    "    X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "    # TODO fit the model\n",
    "\n",
    "    # TODO compute the train and test accuracies\n",
    "    acc_train = ...\n",
    "    acc_test = ...\n",
    "\n",
    "    # print accuracies\n",
    "    print(f\"Train accuracy: {acc_train:.3f}\")\n",
    "    print(f\"Test accuracy:  {acc_test:.3f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this function to test a logistic regression model ([`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = brain_df\n",
    "y = pheno_df[\"DX_GROUP\"]  # diagnosis\n",
    "\n",
    "# TODO define your model\n",
    "model = ...\n",
    "\n",
    "# TODO call train_and_test_model() with the appropriate arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "What do the train and test accuracies tell us? \n",
    "\n",
    "What can we try to improve test performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try predicting scan site instead of diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we try predicting another variable instead: scan site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = brain_df  # same input data\n",
    "y = pheno_df[\"SITE_ID\"]  # scan site\n",
    "y = pd.Series(LabelEncoder().fit_transform(y))  # encode sites as integers\n",
    "\n",
    "# TODO: define your model\n",
    "model = ...\n",
    "\n",
    "# TODO call train_and_test_model() with the appropriate arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "What do these performance metrics tell us?\n",
    "\n",
    "How do we know if this is a good model? What is the chance performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Model selection and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a more stable estimate of a model's generalization ability by using cross-validation instead of a single test set.\n",
    "\n",
    "Update/complete the `cross_validate_model` function below to use the [`StratifiedKFold` class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) to create cross-validation splits for the dataset, then train and test models separately for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def cross_validate_model(\n",
    "    model,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=123,\n",
    "):\n",
    "    \"\"\"Train and test a scikit-learn model with cross-validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        The scikit-learn model to be trained and tested\n",
    "    X : pd.DataFrame\n",
    "        Input features\n",
    "    y : pd.Series\n",
    "        Output labels\n",
    "    n_splits : int, optional\n",
    "        Number of folds for cross-validation, by default 5\n",
    "    shuffle : bool, optional\n",
    "        Whether to shuffle the data before splitting, by default True\n",
    "    random_state : int, optional\n",
    "        Seed to force the shuffle to be the same each time, by default 123\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The fitted models\n",
    "    \"\"\"\n",
    "    # create lists to store results for each fold\n",
    "    fitted_models = []\n",
    "    accs_train = []\n",
    "    accs_test = []\n",
    "\n",
    "    # TODO create a StratifiedKFold cross-validator object\n",
    "    # make sure to use the n_splits, shuffle, and random_state variables\n",
    "    cv = ...\n",
    "\n",
    "    # TODO iterate over the folds\n",
    "    # Hint: look at the documentation of StratifiedKFold\n",
    "    for train_index, test_index in ...:\n",
    "\n",
    "        # TODO get the train and test sets using the indices\n",
    "        # hint: X and y and pandas objects, you can use .iloc[] on them\n",
    "        X_train = ...\n",
    "        X_test = ...\n",
    "        y_train = ...\n",
    "        y_test = ...\n",
    "\n",
    "        # get a fresh (unfitted) model\n",
    "        model = clone(model)\n",
    "\n",
    "        # TODO fit the model\n",
    "\n",
    "        # TODO get the train and test accuracies\n",
    "        acc_train = ...\n",
    "        acc_test = ...\n",
    "\n",
    "        # append results\n",
    "        fitted_models.append(model)\n",
    "        accs_train.append(acc_train)\n",
    "        accs_test.append(acc_test)\n",
    "\n",
    "    # report the mean accuracies\n",
    "    accs_train = np.array(accs_train)\n",
    "    accs_test = np.array(accs_test)\n",
    "    print(f\"Train accuracy: {accs_train.mean():.3f} ± {accs_train.std():.3f}\")\n",
    "    print(f\"Test accuracy:  {accs_test.mean():.3f} ± {accs_test.std():.3f}\")\n",
    "\n",
    "    return fitted_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our new cross-validation function to predict scan site again, but let's switch it up a bit and use Support Vector Machines (implemented as `sklearn.svm.SVC`) instead of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = brain_df\n",
    "y = pheno_df[\"SITE_ID\"]  # scanning site\n",
    "y = pd.Series(LabelEncoder().fit_transform(y))  # encode as integers\n",
    "\n",
    "# TODO: define your model\n",
    "model = ...\n",
    "\n",
    "# TODO call cross_validate_model() with the appropriate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the models we are using have arguments that can be specified when defining/instantiating the model. For example `SVC` has a regularization **hyperparameter** called `C`. Changing the value of `C` may change the model's performance, but doing so in a trial-and-error way leads to implicit data leakage (can you think of why?).\n",
    "\n",
    "Sklearn's `GridSearchCV` class allows us to specify a hyperparameter grid to search over when fitting the data. The test data is not used during that process. Let's use `GridSearchCV` to test several values of `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "\n",
    "Note: what `GridSearchCV` does is called **inner** cross-validation, which should not be confused with the cross-validation done in `cross_validate_model`. Inner cross-validation is used to choose the best set of hyperparameters for a model, while outer cross-validation is used for getting a measure of model generalizability on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = brain_df\n",
    "y = pheno_df[\"SITE_ID\"]  # scanning site\n",
    "y = pd.Series(LabelEncoder().fit_transform(y))  # encode as integers\n",
    "\n",
    "# TODO: define your model\n",
    "model = ...\n",
    "\n",
    "# TODO call cross_validate_model() with the appropriate parameters\n",
    "models = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the `C` that was chosen for each CV fold. Is it the same for all folds?\n",
    "\n",
    "Hint: What does the `cross_validate_model` function return?\n",
    "\n",
    "Hint: Look at the [`GridSearchCV` documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to see how to access the best estimator for each fold.\n",
    "\n",
    "Hint: The documentation for the [`SVC` class](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) may also be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "How should we go about comparing different models (e.g. `LogisticRegression` vs `SVC`?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlsc612",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
