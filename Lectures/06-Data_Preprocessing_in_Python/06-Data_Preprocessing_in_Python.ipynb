{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dApheqXqV-Tf"
   },
   "source": [
    "# Data preprocessing: more art than science?\n",
    "### Written by Nadia Blostein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-R_4TaoV-Th"
   },
   "source": [
    "## Contents of this notebook:\n",
    "<ol>\n",
    "<li>Load and examine your data</li>\n",
    "<li>Data reformatting</li>\n",
    "<li>Data filtering</li>\n",
    "<li>Data transforms</li>\n",
    "<li>Data visualization</li>\n",
    "<li>Examining 2D images</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JrpQkXhYLKm"
   },
   "source": [
    "# Setup\n",
    "Fetch the dataset that you'll be working with throughout this assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PiZxGN8YY7t"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NadiaBlostein/Open-Access-HCP-Data.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1L4WX4C_Synu"
   },
   "source": [
    "Examine your directory structure with the `ls` command. To invoke this command from a jupyter notebook in Google Colab, the `ls` command should be preceded with `!`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1foEjAGSguZ"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVQjjmXWSHvo"
   },
   "source": [
    "Change the working directory of the notebook to within the folder `Open-Access-HCP-Data`. The `cd` command should be preceded with `%`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qW23_nXkZRKn"
   },
   "outputs": [],
   "source": [
    "%cd Open-Access-HCP-Data \n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYL3sxnFSyUV"
   },
   "source": [
    "In this assignment, we will be working with data from the Human Connectome Project (HCP). You can read more about the data [here](https://github.com/NadiaBlostein/McMedHacks2022_Prep_Week_3_Assignment#readme). Specifically, you will preprocess `.csv` (in the `HCP_csv_data` folder) and `.png` files (in the `HCP_2D_slices_MRI_data` folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KmjJboZTW1Z"
   },
   "outputs": [],
   "source": [
    "!ls HCP_2D_slices_MRI_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMJ-aUYRTZvo"
   },
   "outputs": [],
   "source": [
    "!ls HCP_csv_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tG2oM0BjV-Ti"
   },
   "source": [
    "# 1. Load and examine your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkzkrh-oV-Tj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"HCP_csv_data/unrestricted_HCP_behavioral.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVkqozdRV-Tk"
   },
   "source": [
    "**Question 1:** How many subjects (rows) and features (columns) do you have?\\\n",
    "_PS: You cannot always assume that your subjects are rows and features are columns, and sometimes there may be strange header rows with useless information that you need to remove._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "eXqY0np7V-Tk"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(f\"Num subjects: {df.shape[0]}\")\n",
    "print(f\"Num features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z5Y3exuzhd-"
   },
   "source": [
    "Feel free to examine your data frame in the empty code cell below. Examples of valuable commands for a preliminary look at one's data frame: `df.info()`, `df.describe()`, `df.columns()`, `df.head()`, `df.tail`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR_zFqfAz7j7"
   },
   "source": [
    "Next, we will select the `Gender` column to count how many instances we have of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnKocnwxV-Tn"
   },
   "outputs": [],
   "source": [
    "print(f\"unique values of column: {df['Gender'].unique()}\") # prints list of unique values in a feature / column\n",
    "print(f\"\\nvalue counts of column:\\n{df['Gender'].value_counts()}\") # counts how many times each unique value in a feature / column occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_d4xPY2Wi5j0"
   },
   "source": [
    "**Question 2:** Is there another way to count how many males and females are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Eqzz3cCx0_nS"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(f\"Number females: {len(df[df['Gender']=='F'])}\")\n",
    "print(f\"Number males: {len(df[df['Gender']=='M'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KU-J4PhjZWd"
   },
   "source": [
    "**Question 3:** Display only the rows associated with female subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "W3W5g75VV-Tn"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df[df['Gender']==\"F\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgl2Bg-zV-Tn"
   },
   "source": [
    "### A side note on documentation\n",
    "Woah! So many columns and abbreviations! What do they all mean? Make sure you know where your [dataset's documentation](https://wiki.humanconnectome.org/display/PublicData/HCP-YA+Data+Dictionary-+Updated+for+the+1200+Subject+Release#HCPYADataDictionaryUpdatedforthe1200SubjectRelease-Instrument:Demographics) is.\n",
    "\n",
    "Unfortunately, thorough documentation is not always available. Some data types are also very field-specific and require the help of experts, which is part of what makes machine learning so wonderfully interdisciplinary.\n",
    "\n",
    "Let's take a look at what features we have here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLwc_rf0j19-"
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMyKyvPtj9cy"
   },
   "source": [
    "**Question 4:** The script above is not printing ALL of the columns... How do we fix that to be able to see all the features in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "3AWelNh_V-To"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "for col in df.columns: print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data reformatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVZ3jtdSV-To"
   },
   "source": [
    "## 2.1 Selecting the features you want to work with:\n",
    "As you saw above, this dataframe has 499 features. Often, you will only want to work with a subset of the features of a dataframe, so you will have to create a new dataframe with this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBMC8C2QV-To"
   },
   "outputs": [],
   "source": [
    "basics = ['Subject','Gender','Age','PSQI_BedTime']\n",
    "df[basics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mve4NaXUV-To"
   },
   "source": [
    "Let's also add all of some cognitive variables to the mix! Specifically, we'll select the measures related to fluid intelligence (they start with `PMAT` for Penn Matrix Test) and impulsivity (they start with `DDisc` for Delay Discounting).\\\n",
    "**Question 5:** Fill in the missing code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSd4Fw-xV-To",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cognition = ['Subject','Gender','Age','PSQI_BedTime']\n",
    "for col in df.columns:\n",
    "    if (col.find(\"PMAT\")!=-1 or col.find(\"DDisc\")!=-1):\n",
    "        # FILL IN THE BLANK. SOLUTION: cognition.append(col)\n",
    "        cognition.append(col)\n",
    "print(f\"List of variables we will be looking at: {cognition}\") # PS: f-strings will be very useful for you in your Python journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TyvOYGOV-To"
   },
   "source": [
    "**Question 6:** Now that we made a list of all of the features we want to examine, select this subset of our data and make it a separate dataframe called `df_cognition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6cc_jyXLV-Tp"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_cognition = df[cognition]\n",
    "df_cognition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crko0pPjV-Tp"
   },
   "outputs": [],
   "source": [
    "df_cognition.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b12RXnhqV-Tp"
   },
   "source": [
    "## 2.2 Merging two dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_rBAqFSV-Tp"
   },
   "source": [
    "For our dataset of 1206 subjects, we have information about their gender, age range and a variety of cognitive measures. It would be interesting to integrate some other data as well. You have been provided with a separate file that contains brain structure volume data obtained from the neuroimaging data of these same subjects (note that not all subjects in the HCP have neuroimaging data) (more information about how these volumes were obtained can be found [here](https://github.com/NadiaBlostein/Open-Access-HCP-Data#readme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0WEmj8XV-Tp"
   },
   "outputs": [],
   "source": [
    "df_volumes = pd.read_csv(\"HCP_csv_data/HCP_volumes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tvCBCVslDLu"
   },
   "source": [
    "**Question 7:** How many subjects and features does `df_volumes` have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IGrxEaawlCwp"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(f\"Num subjects: {df_volumes.shape[0]}\")\n",
    "print(f\"Num features: {df_volumes.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAvipapJlXhm"
   },
   "source": [
    "**Question 8:** Print the mean and standard deviation of total brain volume (TBV) of this sample. Note that the unit is in mm$^{3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_MU4Tnw5V-Tp"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(f\"Mean TBV: {df_volumes['TBV'].mean()} mm3\")\n",
    "print(f\"TBV standard deviation: {df_volumes['TBV'].std()} mm3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:** Can you round it to two decimal places?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(f\"Mean TBV: {round(df_volumes['TBV'].mean(),2)} mm3\")\n",
    "print(f\"TBV standard deviation: {round(df_volumes['TBV'].std(),2)} mm3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M59oqzyHV-Tp"
   },
   "source": [
    "**Question 10:** List all the subjects whose TBV is above average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Sv17Js45V-Tq"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_volumes[df_volumes['TBV']>df_volumes['TBV'].mean()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63BHKuYDV-Tq"
   },
   "source": [
    "Ok! Let's merge our dataframes. One problem is that our behavioral data has 1206 subjects and our volume data has 1086 subjects. \n",
    "\n",
    "**Question 11:** Create a new dataframe called `df_final` where we only keep the subjects for which we have all of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "bF-AXKccV-Tq"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final=pd.merge(df_cognition,df_volumes, on='Subject')\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYLNBLnJmLcJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41UPVZxeV-Tq"
   },
   "source": [
    "Mission accomplished! We have 1086 and 35 features. However, we would normally expect 36 features (22 features from `df_cognition` and 14 features from `df_volumes`).\\\n",
    "**Question 12:** Why do we only have 35 features in `df_final`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION\\\n",
    "Because `df_cognition` and `df_volumes` have 1 column in common, `Subject`. In fact, we already told the pandas `merge` method to merge the two dataframes along this shared column. Luckily, this method is smart enough not to repeat a shared column in the new dataframe!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Removing features that you do not need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UkGHuy8IgBd"
   },
   "source": [
    "**Question 13:** Complete the following code in order to find and remove any duplicate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BlCUoH3wJk_V"
   },
   "outputs": [],
   "source": [
    "cols_to_drop=[]\n",
    "for i in range(df_final.shape[1]):\n",
    "    for j in range(i+1,df_final.shape[1]):\n",
    "        col1=df_final.columns[i]\n",
    "        col2=df_final.columns[j]\n",
    "        if (df_final[col1].equals(df_final[col2])):\n",
    "            print(f\"Duplicate columns: {col1, col2}\")\n",
    "            cols_to_drop.append(col2)\n",
    "# FILL IN THE BLANK. SOLUTION: df_final.drop(cols_to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykIY0AwO29no"
   },
   "outputs": [],
   "source": [
    "print(df_final.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kk9oZn8rV-Tr"
   },
   "source": [
    "# 3.2 Making your data machine-readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p9y9UQmV-Tr"
   },
   "source": [
    "To be machine-readable, your variables need to be numerical. Want to check?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1rD_Qg7vV-Tr"
   },
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFQsnbWlV-Tr"
   },
   "source": [
    "We have 3 columns that are non-numerical (meaning that they are neither floats nor integers): `Gender`,`Age`,`PSQI_BedTime`. Let's figure out how to handle them, one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDMZGn-7V-Tr"
   },
   "source": [
    "### One-hot encoding or binarizing your data\n",
    "First, we know that the `Gender` column is categorical and has two unique values: `M` or `F`. \n",
    "\n",
    "**Question 14:** Replace all of your `M` values with 1 and `F` values with 2. Hint: `.replace()` can be quite helpful. \\\n",
    "_PS: Make sure to SAVE your data preprocessing code. If ever you forget what number you assigned to what value in the `Gender` category, you will always be able to look back at your code!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Oa77oNphV-Tr"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final['Gender'] = df_final['Gender'].replace('M',1)\n",
    "df_final['Gender'] = df_final['Gender'].replace('F',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q22Um_pUV-Tr"
   },
   "source": [
    "However, suppose that you actually had more than 2 numerical values for this feature (e.g. `M`,`F`,`other`). If you just convert categorical variables to numerical values (ex: `M`=1,`F`=2,`other`=3), you give a \"distance\" to the relationship between variables. For instance, since 1 is closer to 2 than to 3, you are telling your machine that `M` is \"closer\" to `F` (`distance = 2 - 1 = 1`) than to `other` (`distance = 3 - 1 = 2`). We want our categories to be independent. That's where one hot encoding comes into play: \"[A representation of categorical variables as binary vectors](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/).\"\n",
    "\n",
    "Let's revert our `Gender` feature back to its original form, and see how to one-hot encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Gender'] = df_final['Gender'].replace(1,'M')\n",
    "df_final['Gender'] = df_final['Gender'].replace(2,'F')\n",
    "\n",
    "one_hot = pd.get_dummies(df_final['Gender'])\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we convert 1 categorical feature into N binary features, where N = number of values that your feature can take on (2 in this example).\\\n",
    "**Question 15:** Add `one_hot` to `df_final` and make sure to drop the `Gender` column (to avoid duplicate information).\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final = df_final.join(one_hot)\n",
    "df_final = df_final.drop('Gender',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you need to reassign your changes to `df_final` (`df_final = `), or they will not get saved. Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xuti0j5VV-Ts"
   },
   "source": [
    "### Parsing strings in your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_Fexj30V-Ts"
   },
   "source": [
    "#### Handling the `Age` feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGTxCDCvV-Ts"
   },
   "source": [
    "Remember that our `Age` feature is also non-numerical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMaLuwlPV-Ts"
   },
   "outputs": [],
   "source": [
    "df_final['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6izSxt7eV-Ts"
   },
   "source": [
    "**Question 16:** For the sake of this exercise, replace 36+ with a range of 36-40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GlY65tn4a0h"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final['Age'] = df_final['Age'].replace(\"36+\",'36-40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSWS24gl4bOz"
   },
   "source": [
    "Our age range values are organized very clearly: `minimum ageâ€“maximum age`. These age range strings can therefore be split around the `-` such that you create two new columns: one for `minimum age` and one for `maximum age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWGKnhdcV-Ts"
   },
   "outputs": [],
   "source": [
    "fix_age = df_final['Age'].str.split('-', 1, expand=True)\n",
    "fix_age.columns = ['min','max']\n",
    "fix_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpPpU5DQnfq9"
   },
   "source": [
    "**Question 17:** In `df_final`, replace the age range string (from the `Age` columne) for each subject with the mean of the subject's respective age range. _Hint: make sure that the `min` and `max` columns of the `fix_age` df are converted to a numberical data type._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Uwor8DLqV-Ts"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "fix_age[\"min\"] = fix_age['min'].astype(float)\n",
    "fix_age[\"max\"] = fix_age['max'].astype(float)\n",
    "fix_age['mean'] = (fix_age['max']+fix_age['min'])/2\n",
    "df_final['Age'] = fix_age['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyE6rGXV4tm6"
   },
   "outputs": [],
   "source": [
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks8toV84V-Ts"
   },
   "source": [
    "#### Handling the `PSQI_BedTime` feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hs_CxE3HV-Ts"
   },
   "source": [
    "Convert your bed time variable from HH:MM:SS to seconds! The next line of code uses some slightly more advanced functions that will not be covered today, but you can walk through it step by step to figure out what each method does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bnziq-1QV-Tt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ftr = [3600,60,1]\n",
    "for i in range(len(df_final['PSQI_BedTime'])):\n",
    "    x = sum([a*b for a,b in zip(ftr, map(int,df_final['PSQI_BedTime'][i].split(':')))])\n",
    "    df_final['PSQI_BedTime'][i] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjuGPr07V-Tt"
   },
   "source": [
    "#### A note on other strings that often crop up in dataframes and need to be replaced with numbers!\n",
    "`df_final = df_final.replace('FALSE',0)` \\\n",
    "`df_final = df_final.replace('TRUE',1)` \\\n",
    "`df_final = df_final.replace(False,0)` \\\n",
    "`df_final = df_final.replace(True,1)` \\\n",
    "`df_final = df_final.replace('0',0)` # example of random spaces \\\n",
    "`df_final = df_final.replace(' ',np.NaN)` # example of random spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQenax9dV-Tt"
   },
   "source": [
    "**Question 18:** Write a quick line of code that makes sure that every column of `df_final` is of type float!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "qu2IPUdZV-Tt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "for col in df_final.columns: df_final[col] = df_final[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP_h6HlKV-Tt"
   },
   "source": [
    "## 3.3 Handling not available (NA) and inf data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfiQZysiV-Tt"
   },
   "source": [
    "Sometimes, Python will convert some of your values to + or - infinity, which will result in downstream errors. Convert them to NA, and then handle them as NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXTXFDNVV-Tt"
   },
   "outputs": [],
   "source": [
    "df_final = df_final.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX2xgJzkV-Tt"
   },
   "source": [
    "Next, you need to deal with your NA values. \n",
    "\n",
    "**Question 19:** How many nas do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "RF_6bB7wV-Tt"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKCftVkdV-Tt"
   },
   "source": [
    "There is a variety of ways to handle NA data. The most simple approach is to replace NA data with the median (or mean) value of the feature of interest. There are [other](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779) [more](https://arxiv.org/abs/1804.11087) sophisticated data imputation techniques out there, many of which actually leverage machine learning tools (so meta)!\n",
    "\n",
    "However, if a feature has too many NAs, you may want to remove it completely. Define a threshold for the minimal number of missing values that qualifies a feature for removal from your dataset. Here, 12 is quite stringent.\n",
    "\n",
    "**Question 20:** Fill in the blank line of the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=12\n",
    "\n",
    "remove_cols = []\n",
    "for i in range(len(df_final.columns)):\n",
    "    if (df_final.iloc[:,i].isnull().sum() >= threshold):\n",
    "        remove_cols.append(df_final.columns[i])\n",
    "# FILL IN THE BLANK. SOLUTION: df_final = df_final.drop(columns=remove_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 21:** Replace the NA values of this dataframe with the feature-specific median (the median is more robust against outliers than the mean is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Lad9NHw9V-Tt"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "for col in df_final.columns: df_final[col].fillna(df_final[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9RH8R3LV-Tu"
   },
   "outputs": [],
   "source": [
    "df_final.isna().sum().sum()\n",
    "# note the difference between df_final.isna().sum() and df_final.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Removing columns with a standard deviation of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 22:** Write a line of code that removes all columns with a standrard deviation of 0. Why do you think we would want to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final = df_final.loc[:, df_final.std() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to make sure everything is behaving as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_final.columns:\n",
    "    if (df_final[col].std()==0): print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You usually need to perform some sort of feature scaling /normalization to make sure that all of your variables are in the same range (this affects gradient-descent-based algorithms and distance-based algorithms).\n",
    "\n",
    "**Min-Max Scaling / Normalization:** X' = (X-Xmin) / (Xmax-Xmin), X' always ends up with a range of \\[0,1\\] \\\n",
    "**Standardization / Standard Scaler / Z-score):** X' = (X-$\\mu$)/$\\sigma$\n",
    "\n",
    "Which to use? Depends on your data! _\"Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution\"_ (from [here](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)). Other [popular scaling techniques](https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/) include the log transform (you often see this with GWAS, ie genome-wide association studies) and dividing your column-wise values by the absolute value of the maximal value of each column (max abs scaler)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxScaled_df_final=(df_final-df_final.min())/(df_final.max()-df_final.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Standard Scaling\\\n",
    "**Question 23:** Implement a line of code that performs the following column-wise z-scoring (X' = (X-$\\mu$)/$\\sigma$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "standardized_df_final=(df_final-df_final.mean())/df_final.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3: Sklearn Min-Max Scaler\\\n",
    "Slightly different from the Min-Max Scaling defined above:\\\n",
    "`\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms=MinMaxScaler()\n",
    "mms.fit(df_final)\n",
    "df_final_mms=mms.transform(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qZ-YOcWV-Tu"
   },
   "source": [
    "# 6. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzQT3zchV-Tu"
   },
   "source": [
    "Data visualization is a wonderful way to get to know your data in order to plan a relevant analysis or find an appropriate machine learning application. [Matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/) are two canonical data visualization tools that you can use in Python. You will be learning more about it on Wednesday (module content can be found [here](https://github.com/neurodatascience/course-materials-2022/tree/main/Lectures/09-Intro_to_Data_Visualization). Below is but a taster for what lies ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L_6wczKV-Tu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fekJR587V-Tv"
   },
   "source": [
    "#### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOwRnWU2V-Tv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_final[\"PSQI_BedTime\"],df_final[\"TBV\"]) # plot (x, y)\n",
    "plt.ylabel(\"Total brain volume (mm3)\") # label the y-axis\n",
    "plt.xlabel(\"Bedtime (seconds)\") # label the x-axis\n",
    "plt.title(\"Total brain volume as a function of bed time\") # title your graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGmR_x-Aq-QB"
   },
   "source": [
    "**Question 24:** Make a scatter plot of total brain volume (TBV) as a function of bed time, by gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "plt.scatter(df_final[\"PSQI_BedTime\"][df_final[\"F\"]==1.0],df_final[\"TBV\"][df_final[\"F\"]==1.0],color='turquoise')\n",
    "    # plot female datapoints first, in turquoise\n",
    "plt.scatter(df_final[\"PSQI_BedTime\"][df_final[\"M\"]==1.0],df_final[\"TBV\"][df_final[\"M\"]==1.0],color='coral')\n",
    "    # plot female datapoints first, in coral\n",
    "plt.ylabel(\"Total brain volume (mm3)\")\n",
    "plt.xlabel(\"Bedtime (seconds)\")\n",
    "plt.title(\"Total brain volume as a function of bed time\")\n",
    "plt.legend(['Females','Males']) # legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhLbR9ZlV-Tw"
   },
   "source": [
    "#### Histogram plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwQf03YAV-Tx"
   },
   "outputs": [],
   "source": [
    "sns.displot(df_final,x='TBV',kind='kde',fill=True) # plot your histogram\n",
    "plt.ylabel(\"Density\") # name y-axis\n",
    "plt.xlabel(\"TBV (mm3)\") # name x-axis\n",
    "plt.title(\"Distribution of total brain volume (TBV) in our sample\") # figure title\n",
    "plt.gcf().set_size_inches(8, 5) # another way to adjust figure size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTA7DWybV-Tx"
   },
   "outputs": [],
   "source": [
    "sns.histplot(df_final,x='Str_Left',fill=True,color='orange')\n",
    "    # first, plot the distribution of the left striatum in orange\n",
    "sns.histplot(df_final,x='Thal_Left',fill=True,color='turquoise')\n",
    "    # second, plot the distribution of the left thalamus volume in turquoise\n",
    "plt.legend(['Left striatum','Left thalamus'])\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(\"Structure-specific volume (mm3)\")\n",
    "plt.title(\"Distribution of different structure volumes in our sample\")\n",
    "plt.gcf().set_size_inches(8, 5) # adjust figure size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvaFPk-5rUrw"
   },
   "source": [
    "**Question 25:** Generate two smoothed and superimposed histograms of bed times in subjects that are above and below 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ju817ns-rV7V"
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "df_final[\"Over 25 years\"]=df_final[\"Age\"]>25\n",
    "sns.displot(df_final,x='TBV',hue='Over 25 years',kind='kde',fill=True)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(\"TBV (mm3)\")\n",
    "plt.title(\"Distribution of total brain volume (TBV) in our sample for people who are below and above 25 years of age\")\n",
    "plt.gcf().set_size_inches(14, 6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7kKZDlFsTlV"
   },
   "source": [
    "Notice that brains seem to shrink with age in our dataset... Let's look at the numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iviSqsSXtFMv"
   },
   "outputs": [],
   "source": [
    "TBV_below_25=df_final['TBV'][df_final[\"Age\"]<=25].mean()\n",
    "TBV_above_25=df_final['TBV'][df_final[\"Age\"]>25].mean()\n",
    "print(f\"Average TBV for people below or equal to 25 years of age: {round(TBV_below_25,0)} mm3\") \n",
    "print(f\"Average TBV for people above 25 years of age: {round(TBV_above_25,0)} mm3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7mhDCIFtdBi"
   },
   "source": [
    "Interesting! However, does our sample actually have a similar amout of people who are below and above the age of 25? \n",
    "\n",
    "**Question 26:** Count how many people are <= 25 years, and how many people are > 25 yrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF6kiQdPtrdt"
   },
   "outputs": [],
   "source": [
    "subj_above_25=df_final[df_final[\"Age\"]>25].shape[0]\n",
    "subj_below_25=df_final[df_final[\"Age\"]<=25].shape[0]\n",
    "print(f\"We have {subj_below_25} subjects below or at 25 years of age and {subj_above_25} subjects above 25 years of age.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Handling 2D Images in Python\n",
    "There are many different Python tools that you can use to convert 2D images into numpy arrays that you can then manipulate in various ways. For more information, check out [10 Python image manipulation tools](https://opensource.com/article/19/3/python-image-manipulation-tools). In the following (brief) tutorial, we will be using **s**ci**k**it image (**sk**image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd HCP_2D_slices_MRI_data\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "filename = 'HCP_102109_T1w_acpc_dc_restore_brain_t1_axial.png'\n",
    "img=io.imread(filename)\n",
    "print(f\"Shape: {img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 27:** Why does is it a tensor with 4 \"channels\"? _Hint: this in a .png, not a .jpg, image!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION.\n",
    "Each one of the 4 channels is a 2D matrix where the x and y coordinates correspond to a location in the 2D image and the actual number corresponds to either a red, green, blue or transparency value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a script that displays all of your axial images!\\\n",
    "_PS: The `glob` Python module can iterate through a directory using Bash!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "images=[]\n",
    "for file in glob.iglob('HCP*axial*png'):\n",
    "    img=io.imread(file) \n",
    "    images.append(img)\n",
    "fig = plt.figure(figsize=(15, 3.5))\n",
    "rows = 1\n",
    "columns = 5\n",
    "for i in range(5):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img=images[i]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Shape: {img.shape}\",size=12) # height x width [x channel]\n",
    "#fig.set_title(\"AXIAL\")\n",
    "plt.suptitle(\"AXIAL VIEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 28:** Write a for loop to load & display all of your **sagittal** and **coronal** views of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "images=[]\n",
    "for file in glob.iglob('HCP*sagittal*png'):\n",
    "    img=io.imread(file) \n",
    "    images.append(img)\n",
    "fig = plt.figure(figsize=(15, 3.5))\n",
    "rows = 1\n",
    "columns = 5\n",
    "for i in range(5):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img=images[i]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Shape: {img.shape}\",size=12) # height x width [x channel]\n",
    "#fig.set_title(\"AXIAL\")\n",
    "plt.suptitle(\"SAGITTAL VIEW\")\n",
    "\n",
    "images=[]\n",
    "for file in glob.iglob('HCP*coronal*png'):\n",
    "    img=io.imread(file) \n",
    "    images.append(img)\n",
    "fig = plt.figure(figsize=(15, 3.5))\n",
    "rows = 1\n",
    "columns = 5\n",
    "for i in range(5):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    img=images[i]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Shape: {img.shape}\",size=12) # height x width [x channel]\n",
    "#fig.set_title(\"AXIAL\")\n",
    "plt.suptitle(\"CORONAL VIEW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week0-3_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
