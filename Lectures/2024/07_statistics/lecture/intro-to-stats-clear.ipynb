{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistics in Python: an introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In part adapted from: \n",
    "* GaÃ«l Varoquaux [Scipy Lecture](https://scipy-lectures.org/packages/statistics/index.html#linear-models-multiple-factors-and-analysis-of-variance)\n",
    "* The fMRI course developed by M. Brett and myself\n",
    "* Many other resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Requirements\n",
    "1. Standard scientific Python environment (numpy, scipy, matplotlib)\n",
    "2. Pandas\n",
    "3. [Statsmodels](https://www.statsmodels.org/stable/index.html)\n",
    "4. [Seaborn](https://seaborn.pydata.org/)\n",
    "\n",
    "**Disclaimer: Gender questions**\n",
    "\n",
    "   Some of the examples of this tutorial are chosen around gender \n",
    "    questions. The reason is that on such questions controlling the truth\n",
    "    of a claim actually matters to many people. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What this will not cover\n",
    "\n",
    "* **Bayesian statistics in Python**:\n",
    "\n",
    "    This chapter does not cover tools for Bayesian statistics.  \n",
    "    Of particular interest for Bayesian modelling is \n",
    "    [PyMC](http://pymc-devs.github.io/pymc),  \n",
    "    which implements a probabilistic programming language in Python.\n",
    "\n",
    "* **Permutation testing** (see sklearn)\n",
    "\n",
    "* **Read a statistics book**:\n",
    "   The [Think stats](http://greenteapress.com/wp/think-stats-2e>)  \n",
    "   book is available as free PDF or in print and is a great \n",
    "   introduction to statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data representation and interaction\n",
    "====================================\n",
    "\n",
    "Data as a table\n",
    "---------------------\n",
    "\n",
    "The setting that we consider for statistical analysis is that of multiple\n",
    "*observations* or *samples* described by a set of different *attributes*\n",
    "or *features*. The data can than be seen as a 2D table, or matrix, with\n",
    "columns giving the different attributes of the data, and rows the\n",
    "observations. For instance, the data contained in\n",
    "[This csv file](https://raw.githubusercontent.com/scipy-lectures/scipy-lecture-notes/master/packages/statistics/examples/brain_size.csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The data in this .csv file looks like:\n",
    "```\n",
    "\"\";\"Gender\";\"FSIQ\";\"VIQ\";\"PIQ\";\"Weight\";\"Height\";\"MRI_Count\"\n",
    "\"1\";\"Female\";133;132;124;\"118\";\"64.5\";816932\n",
    "\"2\";\"Male\";140;150;124;\".\";\"72.5\";1001121\n",
    "\"3\";\"Male\";139;123;150;\"143\";\"73.3\";1038437\n",
    "\"4\";\"Male\";133;129;128;\"172\";\"68.8\";965353\n",
    "\"5\";\"Female\";137;132;134;\"147\";\"65.0\";951545\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The pandas data-frame\n",
    "\n",
    "\n",
    "We will store and manipulate this data in a\n",
    "    `pandas.DataFrame`, from the [pandas](http://pandas.pydata.org) module. It is the Python equivalent of\n",
    "    the spreadsheet table. It is different from a 2D ``numpy`` array as it\n",
    "    has named columns, can contain a mixture of different data types by\n",
    "    column, and has elaborate selection and pivotal mechanisms.\n",
    "\n",
    "\n",
    "### Creating dataframes: reading data files or converting arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "csvfile = (\n",
    "    \"https://raw.githubusercontent.com/scipy-lectures/\"\n",
    "    \"scipy-lecture-notes/master/packages/statistics/examples/brain_size.csv\"\n",
    ")\n",
    "\n",
    "data = pandas.read_csv(csvfile, sep=\";\", index_col=0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"What type is data ? : \", type(data))\n",
    "print(\"It stores values in a numpy array:\", type(data.values))\n",
    "data.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### warning: Missing values\n",
    "\n",
    "\n",
    "The weight of the second individual is missing in the CSV file. In this\n",
    "  particular file, missing values are represented by \"`.`\". If we don't specify\n",
    "  the missing value (NA = not available) marker, pandas will not recognize this\n",
    "  and we will not be able to do statistical analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv(csvfile, sep=\";\", na_values=\".\")\n",
    "data.head(5)  # .dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating from arrays\n",
    "\n",
    "A `pandas.DataFrame` can also be seen as a dictionary of 1D 'series', eg arrays or lists. If we have 3\n",
    "``numpy`` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = np.linspace(-6, 6, 20)\n",
    "sin_t = np.sin(t)\n",
    "cos_t = np.cos(t)\n",
    "\n",
    "# We can expose them as a :class:`pandas.DataFrame`::\n",
    "pandas.DataFrame({\"t\": t, \"sin\": sin_t, \"cos\": cos_t}).head(4)\n",
    "\n",
    "# Question : what is the first argument ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Manipulating data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"data.shape: \", data.shape)\n",
    "print(\"data.columns: \", data.columns)  # It has columns\n",
    "print(\"\\nFemale VIQ mean: \", data[data[\"Gender\"] == \"Female\"][\"VIQ\"].mean())\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Question: Will we get the same results with :\n",
    "# `data.dropna().describe()` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# \"Group by\"\n",
    "groupby_gender = data.groupby(\"Gender\")\n",
    "for gender, value in groupby_gender[\"VIQ\"]:\n",
    "    print((gender, value.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = groupby_gender.get_group(\"Female\")\n",
    "tmp.head()\n",
    "# groupby_gender.head(7)\n",
    "# [print(item) for item in groupby_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "type(groupby_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[data[\"Gender\"] == \"Female\", \"VIQ\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for gender, value in groupby_gender[\"VIQ\"]:\n",
    "    print((gender, value.mean()))\n",
    "\n",
    "data[\"VIQ\"] += 1\n",
    "\n",
    "# Question : what if we look at the groupby_gender object ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for gender, value in groupby_gender[\"VIQ\"]:\n",
    "    print((gender, value.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* What is the mean value for VIQ for the full population?\n",
    "* How many males/females were included in this study?\n",
    "\n",
    "  **Hint** use 'tab completion' to find out the methods that can be\n",
    "  called, instead of 'mean' in the above example.\n",
    "\n",
    "* What is the average value of MRI counts expressed in log units, for\n",
    "  males and females?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import plotting as pdplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pdplt.scatter_matrix(data[[\"PIQ\", \"VIQ\", \"FSIQ\"]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The IQ metrics are bimodal, as if there are 2 sub-populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesis testing: comparing two groups\n",
    "\n",
    "\n",
    "For simple statistical tests:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Statistical_hypothesis_testing\n",
    "\n",
    "we will use the `scipy.stats` sub-module of [scipy](http://docs.scipy.org/doc/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy import stats as sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cohen's d effect size : \n",
    "\n",
    "$\\hspace{3cm} d = \\frac{\\mu}{\\sigma}$\n",
    "\n",
    "$\\mu$ the non normalized effect size, $\\sigma$ the standard deviation of the **data**\n",
    "\n",
    "Author report: APOE effect on hippocampal volume has a p value of 6.6311e-10, n=733\n",
    "What is the effect size of APOE on the hippocampal volume ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create a normal(0,1) variable\n",
    "n01 = sst.norm(0, 1.0)\n",
    "# n01 = sst.t(df=733)\n",
    "\n",
    "z = n01.isf(6.6311e-10)\n",
    "\n",
    "# wat = n01.cdf(6.6311e-10)\n",
    "\n",
    "d = n01.isf(6.6311e-10) / np.sqrt(733)\n",
    "print(\"z = {:4.3f} d = {:4.3f}\".format(z, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n01.rvs(size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# scipy stats has a great number of distribution, all with pdf cdf, sf, isf, etc ...\n",
    "# but you can also sample from these:\n",
    "n, start, width = 1000, 10, 20\n",
    "unif10_20 = sst.uniform(loc=start, scale=width)\n",
    "data_uniform = unif10_20.rvs(size=(n,))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.distplot(\n",
    "    data_uniform,\n",
    "    bins=50,\n",
    "    #                  kde=True,\n",
    "    color=\"skyblue\",\n",
    "    hist_kws={\"linewidth\": 15, \"alpha\": 1},\n",
    ")\n",
    "ax.set(xlabel=\"Uniform Distribution \", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](stats-distrib.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Student's t-test: the simplest statistical test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`scipy.stats.ttest_1samp` tests if the population mean of data is\n",
    "likely to be equal to a given value (technically if observations are\n",
    "drawn from a Gaussian distributions of given population mean). It returns\n",
    "the [T statistic](https://en.wikipedia.org/wiki/Student%27s_t-test),\n",
    "and the [p-value](https://en.wikipedia.org/wiki/P-value) (see the\n",
    "function's help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_1samp(data[\"VIQ\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Definition of a p-value\n",
    "\n",
    "\n",
    "Probability of observing a statistic equal to the one seen \n",
    "in the data, or one that is more extreme, when the null \n",
    "hypothesis is true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Requires:\n",
    "* Knowledge of the null hypothesis\n",
    "* Choice of a statistic\n",
    "* Concept of repeating the whole study in the same way\n",
    "    - Same study design\n",
    "    - Same sampling scheme\n",
    "    - Same definition of the statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2-sample t-test: testing for difference across populations\n",
    "\n",
    "We have seen above that the mean VIQ in the  male and  \n",
    "female populations were different. To test if this is  \n",
    "significant, we do a 2-sample t-test with  \n",
    "\n",
    "`scipy.stats.ttest_ind`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)  # he non !\n",
    "\n",
    "female_viq = data[data[\"Gender\"] == \"Female\"][\"VIQ\"]\n",
    "male_viq = data[data[\"Gender\"] == \"Male\"][\"VIQ\"]\n",
    "stats.ttest_ind(female_viq, male_viq)\n",
    "\n",
    "# stats.ttest_ind?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Paired tests: repeated measurements on the same individuals\n",
    "\n",
    "PIQ, VIQ, and FSIQ give 3 measures of IQ.  \n",
    "Let us test if FISQ and PIQ are significantly  \n",
    "different. We can use a 2 sample test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Box plots of different columns for each gender\n",
    "groupby_gender.boxplot(column=[\"FSIQ\", \"VIQ\", \"PIQ\"])\n",
    "groupby_gender.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "stats.ttest_ind(data[\"FSIQ\"], data[\"PIQ\"])\n",
    "\n",
    "# Can you see a problem with this approach ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The problem with this approach is that it forgets that there are links between  \n",
    "observations: FSIQ and PIQ are measured on the same individuals. Thus the  \n",
    "variance due to inter-subject variability is confounding, and can be removed,  \n",
    "using a \"paired test\", or [\"repeated measures test\"](https://en.wikipedia.org/wiki/Repeated_measures_design)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# considering that FSIQ and PIQ come from the same participants:\n",
    "\n",
    "stats.ttest_rel(data[\"FSIQ\"], data[\"PIQ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This is equivalent to a 1-sample test on the difference:\n",
    "\n",
    "stats.ttest_1samp(data[\"FSIQ\"] - data[\"PIQ\"], 0)\n",
    "\n",
    "# stats.ttest_1samp?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "T-tests assume Gaussian errors.  \n",
    "\n",
    "We can use a [Wilcoxon signed-rank test](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) that relaxes this assumption:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "stats.wilcoxon(data[\"FSIQ\"], data[\"PIQ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "* Test the difference between weights in males and females.\n",
    "* Use non parametric statistics to test the difference  \n",
    "  between VIQ in males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pandas.read_csv(csvfile, sep=\";\", na_values=\".\")\n",
    "\n",
    "model = ols(\"VIQ ~ Gender + MRI_Count + Height\", data).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Here, we don't need to define a contrast, as we are testing a single\n",
    "# coefficient of our model, and not a combination of coefficients.\n",
    "# However, defining a contrast, which would then be a 'unit contrast',\n",
    "# will give us the same results\n",
    "print(model.f_test([0, 1, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Here we plot a scatter matrix to get intuitions on our results.\n",
    "# This goes beyond what was asked in the exercise\n",
    "\n",
    "# This plotting is useful to get an intuitions on the relationships between\n",
    "# our different variables\n",
    "\n",
    "from pandas import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fill in the missing values for Height for plotting\n",
    "data[\"Height\"].fillna(method=\"pad\", inplace=True)\n",
    "\n",
    "# The parameter 'c' is passed to plt.scatter and will control the color\n",
    "# The same holds for parameters 'marker', 'alpha' and 'cmap', that\n",
    "# control respectively the type of marker used, their transparency and\n",
    "# the colormap\n",
    "plotting.scatter_matrix(\n",
    "    data[[\"VIQ\", \"MRI_Count\", \"Height\"]],\n",
    "    c=(data[\"Gender\"] == \"Female\"),\n",
    "    marker=\"o\",\n",
    "    alpha=1,\n",
    "    cmap=\"winter\",\n",
    ")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(\"blue: male, green: female\", size=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear models, multiple factors, and analysis of variance\n",
    "\n",
    "## \"formulas\" to specify statistical models in Python\n",
    "\n",
    "### A simple linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Generate and show the data\n",
    "x = np.linspace(-5, 5, 20)\n",
    "\n",
    "# To get reproducible values, provide a seed value\n",
    "np.random.seed(1)\n",
    "\n",
    "y = -5 + 3 * x + 4 * np.random.normal(size=x.shape)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(x, y, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Multilinear regression model, calculating fit, P-values,\n",
    "# confidence intervals etc.\n",
    "\n",
    "# Convert the data into a Pandas DataFrame to use the formulas\n",
    "# framework in statsmodels\n",
    "data = pandas.DataFrame({\"x\": x, \"y\": y})\n",
    "\n",
    "# Fit the model\n",
    "model = ols(\"y ~ x\", data).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Peform analysis of variance on fitted linear model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "# print('\\nANOVA results')\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Statsmodels uses a statistical terminology: the `y` variable in\n",
    "statsmodels is called 'endogenous' while the `x` variable is called\n",
    "exogenous.  This is discussed in more detail in  \n",
    "http://statsmodels.sourceforge.net/devel/endog_exog.html\n",
    "\n",
    "To simplify, `y` (endogenous) is the value you are trying to predict,\n",
    "while `x` (exogenous) represents the features you are using to make\n",
    "the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Retrieve the estimated parameters from the model above. \n",
    "\n",
    "\n",
    "   **Hint**: use tab-completion to find the relevent attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# model.model.exog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical variables: comparing groups or multiple categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# remember, we modified \"data\" !\n",
    "data = pandas.read_csv(csvfile, sep=\";\", na_values=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = ols(\"VIQ ~ Gender + 1\", data)\n",
    "modelfit = model.fit()\n",
    "print(modelfit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.exog_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Forcing categorical**:\n",
    "\n",
    "the 'Gender' is automatically detected as a\n",
    "categorical variable, and thus each of its different values are\n",
    "treated as different entities.\n",
    "\n",
    "An integer column can be forced to be treated as categorical using:\n",
    "\n",
    "    model = ols('VIQ ~ C(Gender)', data).fit()\n",
    "\n",
    "\n",
    "**Intercept**:\n",
    "\n",
    "We can remove the intercept using `- 1` in the formula,\n",
    "or force the use of an intercept using `+ 1`.\n",
    "\n",
    "\n",
    "By default, statsmodels treats a categorical variable with K possible\n",
    "values as K-1 'dummy' boolean variables (the last level being\n",
    "absorbed into the intercept term).  This is almost always a good\n",
    "default choice - however, it is possible to specify different\n",
    "encodings for categorical variables\n",
    "(http://statsmodels.sourceforge.net/devel/contrasts.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Link to t-tests between different FSIQ and PIQ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# To compare different types of IQ, we need to create a \"long-form\"\n",
    "# table, listing IQs, where the type of IQ is indicated by a\n",
    "# categorical variable::\n",
    "\n",
    "data_fisq = pandas.DataFrame({\"iq\": data[\"FSIQ\"], \"type\": \"fsiq\"})\n",
    "data_piq = pandas.DataFrame({\"iq\": data[\"PIQ\"], \"type\": \"piq\"})\n",
    "data_long = pandas.concat((data_fisq, data_piq))\n",
    "\n",
    "print(data_long)\n",
    "\n",
    "# some_rows = (np.random.random_sample(data_long.shape[0]) < .15)\n",
    "# print(data_long.loc[some_rows, 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = ols(\"iq ~ type\", data_long).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# same values\n",
    "stats.ttest_ind(data[\"PIQ\"], data[\"FSIQ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    " Going back to the brain size + IQ data, test if the VIQ of male and\n",
    " female are different after removing the effect of brain size, height\n",
    "   and weight.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv(csvfile, sep=\";\", na_values=\".\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "modelfit = ols(\"VIQ ~ Weight + Height + MRI_Count + Gender\", data).fit()\n",
    "modelfit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "modelfit = ols(\"VIQ ~ Weight + Height + MRI_Count*Gender - 1\", data).fit()\n",
    "modelfit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(modelfit.f_test([1, -1, 0, 0, 0, 0]))\n",
    "print(modelfit.f_test([[0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# modelfit.model.exog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Winner's curse effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate one experiment  \n",
    "* n samples, alpha type I error, normal distribution, mean, sigma are parameters (start with parameters: 'n':30, 'mu':.25, 'sigma': 1., 'alpha': 0.05)\n",
    "* test if the mean of the simulated sample is equal to zero (our null hypothesis) controlling for the type I error\n",
    "\n",
    "## Simulate N_exp experiments\n",
    "* launch N_exp of these simulations\n",
    "* record the results - if the test is significant, store the mean of the sample in a numpy array named `published`\n",
    "* compare original mean (eg. 25) with the `published` values\n",
    "\n",
    "## What if ...\n",
    "* n sample is smaller ?\n",
    "* alpha is more strict ?\n",
    "* effect size (the mean of the normal) is greater ? smaller ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Robust statistics with statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# data = sm.datasets.stackloss.load()\n",
    "data = modelfit.model\n",
    "huber_t = sm.RLM(data.endog, data.exog, M=sm.robust.norms.HuberT())\n",
    "hub_results = huber_t.fit()\n",
    "print(hub_results.params)\n",
    "print(hub_results.bse)\n",
    "print(hub_results.summary(yname=\"y\", xname=data.exog_names))\n",
    "#           xname=['var_{:d}'.format(i) for i in range(len(hub_results.params))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nsample = 50\n",
    "x1 = np.linspace(0, 20, nsample)\n",
    "X = np.asarray([x1, (x1 - 5) ** 2]).T\n",
    "X = sm.add_constant(X)\n",
    "sig = 0.3  # smaller error variance makes OLS<->RLM contrast bigger\n",
    "beta = [5, 0.5, -0.0]\n",
    "y_true2 = np.dot(X, beta)\n",
    "y2 = y_true2 + sig * 1.0 * np.random.normal(size=nsample)\n",
    "y2[[39, 41, 43, 45, 48]] -= 5  # add some outliers (10% of nsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "modelfit = sm.OLS(y2, X).fit()\n",
    "print(modelfit.params)\n",
    "print(modelfit.bse)\n",
    "# print(modelfit.predict() - y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "modelfit_rlm = sm.RLM(y2, X).fit()\n",
    "print(modelfit_rlm.params)\n",
    "print(modelfit_rlm.bse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x1, y2, \"o\", label=\"data\")\n",
    "ax.plot(x1, y_true2, \"b-\", label=\"True\")\n",
    "predict_std, conf_lower, conf_upper = wls_prediction_std(modelfit)\n",
    "\n",
    "ax.plot(x1, modelfit.fittedvalues, \"r-\", label=\"OLS\")\n",
    "ax.plot(x1, conf_upper, \"r--\")\n",
    "ax.plot(x1, conf_lower, \"r--\")\n",
    "ax.plot(x1, modelfit_rlm.fittedvalues, \"g.-\", label=\"RLM\")\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wls_prediction_std?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\newcommand{L}[1]{\\| #1 \\|}\\newcommand{VL}[1]{\\L{ \\vec{#1} }}\\newcommand{R}[1]{\\operatorname{Re}\\,(#1)}\\newcommand{I}[1]{\\operatorname{Im}\\, (#1)}$\n",
    "\n",
    "# Correlated regressors\n",
    "\n",
    "Load and configure libraries:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt\n",
    "# Make numpy print 4 significant digits for prettiness\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "# Seed random number generator\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Imagine we have a TR (image) every 2 seconds, for 30 seconds. Here are\n",
    "the times of the TR onsets, in seconds:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "times = np.arange(0, 30, 2)\n",
    "times"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we make a function returning an HRF shape for an input vector of\n",
    "times:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Gamma distribution from scipy\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "def spm_hrf(times):\n",
    "    \"\"\" Return values for SPM-like HRF at given times \"\"\"\n",
    "    # Make output vector\n",
    "    values = np.zeros(len(times))\n",
    "    # Only evaluate gamma above 0 (undefined at <= 0)\n",
    "    valid_times = times[times > 0]\n",
    "    # Gamma pdf for the peak\n",
    "    peak_values = gamma.pdf(valid_times, 6)\n",
    "    # Gamma pdf for the undershoot\n",
    "    undershoot_values = gamma.pdf(valid_times, 12)\n",
    "    # Combine them, put back into values vector\n",
    "    values[times > 0] = peak_values - 0.35 * undershoot_values\n",
    "    # Scale area under curve to 1\n",
    "    return values / np.sum(values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sample the HRF at the given times (to simulate an event starting at time\n",
    "0), and at times - 2 (simulating an event starting at time 2):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "hrf1 = spm_hrf(times)\n",
    "hrf2 = spm_hrf(times - 2) # An HRF with 2 seconds (one TR) delay\n",
    "hrf1 = (hrf1 - hrf1.mean()) # Rescale and mean center\n",
    "hrf2 = (hrf2 - hrf2.mean())\n",
    "plt.plot(times, hrf1)\n",
    "plt.plot(times, hrf2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Pearson correlation coefficient between the HRFs for the two events:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "np.corrcoef(hrf1, hrf2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a signal that comes from the combination of the two HRFs:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "signal = hrf1 + hrf2\n",
    "plt.plot(hrf1, label='hrf1')\n",
    "plt.plot(hrf2, label='hrf2')\n",
    "plt.plot(signal, label='signal (combined hrfs)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Weâre going to make our simulated data from taking the signal (the two HRFs)\n",
    "and adding some random noise:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "noise = np.random.normal(size=times.shape)\n",
    "Y = signal + noise\n",
    "plt.plot(times, signal)\n",
    "plt.plot(times, Y, '+')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are going to model this simulated signal in several different ways.  First,\n",
    "we make a model that only has the first HRF as a regressor (plus a column of\n",
    "ones to model the mean of the data):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "X_one = np.vstack((hrf1, np.ones_like(hrf1))).T\n",
    "plt.imshow(X_one, interpolation='nearest', cmap='gray')\n",
    "plt.title('Model with first HRF regressor only')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next we make a model where we also include the second HRF as a regressor:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "X_both = np.vstack((hrf1, hrf2, np.ones_like(hrf1))).T\n",
    "plt.imshow(X_both, interpolation='nearest', cmap='gray')\n",
    "plt.title('Model with both HRF regressors')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we make a very large number of data vectors, each with the signal\n",
    "(both HRFs) plus a different vector of noise."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "T = len(times)\n",
    "iters = 10000\n",
    "# Make 10000 Y vectors (new noise for each colum)\n",
    "noise_vectors = np.random.normal(size=(T, iters))\n",
    "# add signal to make data vectors\n",
    "Ys = noise_vectors + signal[:, np.newaxis]\n",
    "Ys.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We first fit the model with only the first HRF regressor to every (signal +\n",
    "noise) sample vector."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Fit X_one to signals + noise\n",
    "B_ones = npl.pinv(X_one).dot(Ys)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next fit the model with both HRFs as regressors:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Fit X_both to signals + noise\n",
    "B_boths = npl.pinv(X_both).dot(Ys)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that the students-t statistic is:\n",
    "\n",
    "$$\n",
    "t = \\frac{c^T \\hat\\beta}{\\sqrt{\\mathrm{var}(c^T \\hat\\beta)}}\n",
    "$$\n",
    "\n",
    "which works out to:\n",
    "\n",
    "$$\n",
    "t = \\frac{c^T \\hat\\beta}{\\sqrt{\\hat{\\sigma}^2 c^T (X^T X)^+ c}}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\sigma}^2$ is our estimate of variance in the residuals, and\n",
    "$(X^T X)^+$ is the [pseudo-inverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_pseudoinverse) of\n",
    "$X^T X$.\n",
    "\n",
    "Thatâs the theory. So, what is the distribution of the estimates we get for\n",
    "the first beta, in the single-HRF model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "plt.hist(B_ones[0], bins=50)\n",
    "print(np.std(B_ones[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The standard deviation of the estimates is what we observe. Does this\n",
    "match what we would predict from the t-statistic formula above?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "C_one = np.array([1, 0])[:, None]  # column vector\n",
    "sig_ones = np.sqrt(C_one.T.dot(npl.pinv(X_one.T.dot(X_one)).dot(C_one)))[0][0]\n",
    "print(sig_ones)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the mean of the estimates, is somewhere above one, even\n",
    "though we only added 1 times the first HRF as the signal:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "print(np.mean(B_ones[0]))\n",
    "t_ones = B_ones/sig_ones\n",
    "t_ones.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is because the single first regresssor has to fit *both* the first HRF in\n",
    "the signal, and as much as possible of the second HRF in the signal, because\n",
    "there is nothing else in the model to fit the second HRF shape.\n",
    "\n",
    "What estimates do we get for the first regressor, when we have both regressors\n",
    "in the model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "plt.hist(B_boths[0], bins=50)\n",
    "print(np.mean(B_boths[0]), np.std(B_boths[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Two things have happened now we added the second (correlated) hrf2 regressor.\n",
    "First, the mean of the parameter for the hrf1 regressor has dropped to 1,\n",
    "because hrf1 is no longer having to model the signal from the second HRF.\n",
    "Second, the variability of the estimate has increased.  This is what the\n",
    "bottom half of the t-statistic predicts:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "C_both = np.array([1, 0, 0])[:, None]  # column vector\n",
    "sig_both = np.sqrt(C_both.T.dot(npl.pinv(X_both.T.dot(X_both)).dot(C_both)))[0][0]\n",
    "\n",
    "print(np.mean(B_boths[0]), np.std(B_boths[0]))\n",
    "\n",
    "t_both_0 = B_boths[0]/sig_both\n",
    "t_both_0.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The estimate of the parameter for hrf2 has a mean of around 1, like the\n",
    "parameter estimates for hrf1. This is what we expect because we have 1 x hrf1\n",
    "and 1 x hrf2 in the signal. Not surprisingly, the hrf2 parameter estimate has\n",
    "a similar variability to that for the hrf1 parameter estimate:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "plt.hist(B_boths[1], bins=50)\n",
    "print(np.mean(B_boths[1]), np.std(B_boths[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "C_both_1 = np.array([0, 1, 0])[:, None]  # column vector\n",
    "np.sqrt(C_both_1.T.dot(npl.pinv(X_both.T.dot(X_both)).dot(C_both_1)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The parameter estimates for hrf1 and hrf2 are anti-correlated:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Relationship of estimated parameter of hrf1 and hrf2\n",
    "plt.plot(B_boths[0], B_boths[1], '.')\n",
    "np.corrcoef(B_boths[0], B_boths[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Orthogonalizing hrf2 with respect to hrf1\n",
    "\n",
    "hrf2 is correlated with hrf1. That means that we can split up hrf2 into two\n",
    "vectors, one being a multiple of hrf1, and the other being the remaining\n",
    "unique contribution of hrf2. The sum of the two vectors is the original hrf2\n",
    "regressor. Like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Regress hrf2 against hrf1 to get best fit of hrf2 using just hrf1\n",
    "y = hrf2\n",
    "X = hrf1[:, np.newaxis]  # hrf1 as column vector\n",
    "B_hrf1_in_hrf2 = npl.pinv(X).dot(y)  # scalar multiple of hrf1 to best fit hrf2\n",
    "hrf1_in_hrf2 = X.dot(B_hrf1_in_hrf2)  # portion of hrf2 that can be explained by hrf1\n",
    "unique_hrf2 = hrf2 - hrf1_in_hrf2  # portion of hrf2 that cannot be explained by hrf1\n",
    "plt.plot(times, hrf1, label='hrf1')\n",
    "plt.plot(times, hrf2, label='hrf2')\n",
    "plt.plot(times, hrf1_in_hrf2, label='hrf1 in hrf2')\n",
    "plt.plot(times, unique_hrf2, label='hrf2 orth wrt hrf1')\n",
    "plt.legend()\n",
    "# hrf1 part of hrf2, plus unique part, equals original hrf2\n",
    "np.allclose(hrf2, hrf1_in_hrf2 + unique_hrf2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How much of the first regressor did we find in the second regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "B_hrf1_in_hrf2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we have the model with both hrf1 and hrf2, we are effectively multiplying\n",
    "both parts of hrf2 by the same beta parameter, to fit the data. That is, we\n",
    "are applying the same scaling to the part of hrf2 that is the same shape as\n",
    "hrf1 and the part of hrf2 that cannot be formed from the hrf1 shape.\n",
    "\n",
    "Now, what happens if we replace hrf2, by just the part of hrf2, that cannot be\n",
    "explained by hrf1? Our second regressor is now hrf2 *orthogonalized with\n",
    "respect to* hrf1:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "X_both_o = np.vstack((hrf1, unique_hrf2, np.ones_like(hrf1))).T\n",
    "plt.imshow(X_both_o, interpolation='nearest', cmap='gray')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "plt.plot(times, X_both_o[:,0], times, X_both_o[:,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What will happen when we fit this model?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "B_boths_o = npl.pinv(X_both_o).dot(Ys)\n",
    "# Distribution of parameter for hrf1 in orth model\n",
    "plt.hist(B_boths_o[0], bins=50)\n",
    "print(np.mean(B_boths_o[0]), np.std(B_boths_o[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Predicted variance of hrf1 parameter is the same as for the\n",
    "# model with hrf1 on its own\n",
    "np.sqrt(C_both.T.dot(npl.pinv(X_both_o.T.dot(X_both_o)).dot(C_both)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The parameter for the hrf1 regressor has now returned to the same value and\n",
    "variance as it had when hrf1 was the only regressor in the model (apart from\n",
    "the mean). For the orthogonalized model, we removed the part of hrf2 that\n",
    "could be explained by hrf1. Now, the amount of hrf1, that we could find in\n",
    "hrf2, has been added back to the parameter for hrf1, in order to make the\n",
    "fitted $\\hat{y}$ values the same as for the model with both HRFs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "np.mean(B_boths[0, :]) + B_hrf1_in_hrf2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The hrf1 parameter in the orthogonalized model is the same as for the model\n",
    "that only includes hrf1 - as if the orthogonalized hrf2 was not present. The\n",
    "parameter for orthogonalized hrf2 is the same as the parameter for hrf2 in the\n",
    "not-orthogonalized model. We still need the same amount of the *orthogonal\n",
    "part* of the second regressor to explain the signal:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example parameters from the single model\n",
    "B_ones[:,:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Example parameters from the non-orth model\n",
    "B_boths[:,:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Example parameters from the orth model\n",
    "B_boths_o[:,:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The parameter for the hrf1 regressor in the orth model\n",
    "# is the same as the parameter for the hrf1 regressor in the\n",
    "# single regressor model\n",
    "plt.plot(B_ones[0], B_boths_o[0], '.')\n",
    "np.allclose(B_ones[0], B_boths_o[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The parameter for the orthogonalized hrf2 regressor is the same as the\n",
    "# parameter for the non-orthogonalize hrf2 regressor in the\n",
    "# non-orthogonalized model\n",
    "plt.plot(B_boths[1], B_boths_o[1], '.')\n",
    "np.allclose(B_boths[1], B_boths_o[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The parameter for the hrf1 regressor in the non-orth model\n",
    "# is correlated with the parameter for the hrf1 regressor\n",
    "# in the orth model.\n",
    "plt.plot(B_boths[0], B_boths_o[0], '.')\n",
    "np.corrcoef(B_boths[0], B_boths_o[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Relationship of estimated parameters for hrf1 and orthogonalized hrf2\n",
    "# (they should be independent)\n",
    "plt.plot(B_boths_o[0], B_boths_o[1], '+')\n",
    "np.corrcoef(B_boths_o[0], B_boths_o[1])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "584.367px",
    "left": "0px",
    "right": "906.333px",
    "top": "110.633px",
    "width": "86px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
